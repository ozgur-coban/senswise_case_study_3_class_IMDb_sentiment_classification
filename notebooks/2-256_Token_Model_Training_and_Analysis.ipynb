{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trlg9QCaHk-0"
      },
      "source": [
        "# Project: IMDb 3-Class Sentiment Analysis\n",
        "# Notebook: 256-Token Model Training and Analysis\n",
        "\n",
        "This notebook contains the complete workflow for the 256-token-length model, which is optimized for training speed.\n",
        "\n",
        "1.  **Data Preparation:** Loads the raw IMDb dataset, tokenizes all text to `max_length=256`, and saves the processed dataset to Google Drive.\n",
        "2.  **Model Training:** Fine-tunes the `bert-base-uncased` model on the 256-token data using high-performance settings (large batch size, AMP, `torch.compile()`).\n",
        "3.  **Binary Evaluation:** Evaluates the trained model for binary (Pos/Neg) accuracy.\n",
        "4.  **Phase 2 Analysis:** Sets up and runs the 3-class heuristic systems (Ratio, Logit, Weighting) on a 1,000-review sample.\n",
        "5.  **Phase 2 Validation:** Runs a final validation of the winning heuristic (System 3) on a larger 10,000-review sample."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H09h2licHk-2"
      },
      "source": [
        "## 1. Setup: Install and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7j5qUAFHk-3"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install transformers datasets accelerate torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxuL2ybeHk-3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_dataset, load_from_disk\n",
        "from google.colab import drive\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "import numpy as np\n",
        "import nltk\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm.auto import tqdm # For progress bars\n",
        "import pandas as pd\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYl9T-xlHk-5"
      },
      "outputs": [],
      "source": [
        "# Helper function to format elapsed time\n",
        "def format_time(elapsed):\n",
        "    '''Takes a time in seconds and returns a string hh:mm:ss'''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54MRmjvuHk-5"
      },
      "source": [
        "## 2. Phase 1: Data Preparation (256-Token)\n",
        "\n",
        "This step loads the raw IMDb dataset, tokenizes all text to a `max_length` of 256, and saves the processed dataset to Google Drive to avoid re-computing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSPcraFNHk-6"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive to access and save project files\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define path to save the processed data\n",
        "save_path_256 = '/content/drive/My Drive/BERT_IMDB_Processed_256'\n",
        "\n",
        "# Load original dataset and tokenizer\n",
        "print(\"Loading IMDb dataset...\")\n",
        "imdb = load_dataset(\"imdb\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Define the 256-token preprocessing function\n",
        "def preprocess_function_256(examples):\n",
        "    \"\"\"Tokenizes text, pads, and truncates to 256 tokens.\"\"\"\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=256  # Set max_length to 256 tokens\n",
        "    )\n",
        "\n",
        "# Apply the function to the entire dataset\n",
        "print(\"Tokenizing and preprocessing dataset to max_length=256...\")\n",
        "tokenized_imdb_256 = imdb.map(preprocess_function_256, batched=True)\n",
        "\n",
        "# Clean up columns for training\n",
        "tokenized_imdb_256 = tokenized_imdb_256.remove_columns([\"text\"])\n",
        "tokenized_imdb_256 = tokenized_imdb_256.rename_column(\"label\", \"labels\")\n",
        "tokenized_imdb_256.set_format(\"torch\")\n",
        "print(\"Preprocessing complete.\")\n",
        "\n",
        "# Save the new 256-token dataset to your Drive\n",
        "print(f\"Saving 256-token dataset to: {save_path_256}\")\n",
        "tokenized_imdb_256.save_to_disk(save_path_256)\n",
        "\n",
        "print(f\"--- Successfully saved 256-token dataset to Google Drive! ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmKSiuSjHk-6"
      },
      "source": [
        "## 3. Phase 1: Model Training (256-Token)\n",
        "\n",
        "This section loads the pre-processed 256-token data, defines the training parameters, and runs the fine-tuning loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utxNgK4RHk-7"
      },
      "outputs": [],
      "source": [
        "# --- 1. Key Parameters ---\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "NUM_WORKERS = 8\n",
        "\n",
        "PREFETCH_FACTOR = 4\n",
        "\n",
        "\n",
        "LEARNING_RATE = 5e-5\n",
        "EPOCHS = 2\n",
        "\n",
        "# Define paths for loading and saving\n",
        "LOAD_PATH = '/content/drive/My Drive/BERT_IMDB_Processed_256'\n",
        "SAVE_PATH = '/content/drive/My Drive/BERT_IMDB_Model_Trained_256_FP16_Optimized'\n",
        "\n",
        "\n",
        "# --- 2. Load Data ---\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(f\"Loading processed data (max_length=256) from: {LOAD_PATH}\")\n",
        "tokenized_imdb = load_from_disk(LOAD_PATH)\n",
        "\n",
        "# --- 3. Set Up DataLoaders ---\n",
        "print(\"Setting up DataLoaders...\")\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_imdb[\"train\"],\n",
        "    shuffle=True,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    prefetch_factor=PREFETCH_FACTOR\n",
        ")\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_imdb[\"test\"],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    prefetch_factor=PREFETCH_FACTOR\n",
        ")\n",
        "print(\"DataLoaders are ready.\")\n",
        "print(f\"Using Batch Size: {BATCH_SIZE}\")\n",
        "print(f\"Training batches: {len(train_dataloader)}\")\n",
        "\n",
        "# --- 4. Define the Model ---\n",
        "print(\"Loading BertForSequenceClassification model...\")\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels=2\n",
        ")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "print(\"Compiling model with torch.compile()... (This may take a moment)\")\n",
        "try:\n",
        "    model = torch.compile(model)\n",
        "    print(\"Model compiled successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"torch.compile() failed: {e}\")\n",
        "    print(\"Continuing without compilation.\")\n",
        "\n",
        "print(f\"Model moved to {device}\")\n",
        "\n",
        "# --- 5. Set up Training Parameters ---\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "total_steps = len(train_dataloader) * EPOCHS\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# --- 6. The OPTIMIZED Training Loop ---\n",
        "print(f\"\\nStarting training with Automatic Mixed Precision for {EPOCHS} epochs...\")\n",
        "\n",
        "for epoch_i in range(0, EPOCHS):\n",
        "    print(f\"\\n======== Epoch {epoch_i + 1} / {EPOCHS} ========\")\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        if step % 100 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print(f'  Batch {step:>5,}  of  {len(train_dataloader):>5,}.    Elapsed: {elapsed}.')\n",
        "\n",
        "        b_input_ids = batch['input_ids'].to(device)\n",
        "        b_input_mask = batch['attention_mask'].to(device)\n",
        "        b_labels = batch['labels'].to(device)\n",
        "        model.zero_grad()\n",
        "\n",
        "\n",
        "        with torch.cuda.amp.autocast():\n",
        "            result = model(b_input_ids,\n",
        "                           token_type_ids=None,\n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "            loss = result.loss\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "    training_time = format_time(time.time() - t0)\n",
        "    print(f\"\\n  Average training loss: {avg_train_loss:.2f}\")\n",
        "    print(f\"  Training epoch took: {training_time}\")\n",
        "\n",
        "print(\"\\n--- Training complete! ---\")\n",
        "\n",
        "# --- 7. Save the trained model to your Drive ---\n",
        "print(f\"Saving model to {SAVE_PATH}\")\n",
        "\n",
        "model_to_save = model._orig_mod if hasattr(model, '_orig_mod') else model\n",
        "model_to_save.save_pretrained(SAVE_PATH)\n",
        "\n",
        "print(\"Saving tokenizer...\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "tokenizer.save_pretrained(SAVE_PATH)\n",
        "print(\"Model and tokenizer saved.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bLqb9ScCHk-7"
      },
      "source": [
        "## 4. Phase 1: Binary Model Evaluation (256-Token)\n",
        "\n",
        "This section evaluates the 256-token model on the 25,000-review test set to get its baseline accuracy, precision, and recall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5NPfvdLHk-8"
      },
      "outputs": [],
      "source": [
        "# --- 1. Key Parameters for Speed ---\n",
        "\n",
        "EVAL_BATCH_SIZE = 256\n",
        "NUM_WORKERS = 8\n",
        "PREFETCH_FACTOR = 4\n",
        "\n",
        "# --- 2. Mount Drive and Define Paths ---\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "data_load_path = '/content/drive/My Drive/BERT_IMDB_Processed_256'\n",
        "model_load_path = '/content/drive/My Drive/BERT_IMDB_Model_Trained_256_FP16_Optimized'\n",
        "\n",
        "# --- 3. Load Model and Tokenizer ---\n",
        "print(f\"Loading trained model from: {model_load_path}\")\n",
        "model = BertForSequenceClassification.from_pretrained(model_load_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_load_path)\n",
        "\n",
        "# --- 4. Load Test Data ---\n",
        "print(f\"Loading processed data from: {data_load_path}\")\n",
        "tokenized_imdb = load_from_disk(data_load_path)\n",
        "\n",
        "# --- 5. Create OPTIMIZED Test DataLoader ---\n",
        "print(\"Setting up optimized Test DataLoader...\")\n",
        "test_dataloader = DataLoader(\n",
        "    tokenized_imdb[\"test\"],\n",
        "    batch_size=EVAL_BATCH_SIZE,\n",
        "    num_workers=NUM_WORKERS,\n",
        "    pin_memory=True,\n",
        "    prefetch_factor=PREFETCH_FACTOR\n",
        ")\n",
        "print(\"Test DataLoader is ready.\")\n",
        "\n",
        "# --- 6. Set Up Evaluation ---\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "\n",
        "print(\"Compiling model with torch.compile()... (This may take a moment)\")\n",
        "try:\n",
        "    model = torch.compile(model)\n",
        "    print(\"Model compiled successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"torch.compile() failed: {e}. Continuing without compilation.\")\n",
        "\n",
        "print(f\"Model moved to {device}. Starting evaluation...\")\n",
        "\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "# --- 7. Optimized Evaluation Loop ---\n",
        "print(\"Starting evaluation...\")\n",
        "t0 = time.time() # Start timer\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "  with torch.cuda.amp.autocast():\n",
        "    for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
        "\n",
        "        b_input_ids = batch['input_ids'].to(device)\n",
        "        b_input_mask = batch['attention_mask'].to(device)\n",
        "        b_labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(b_input_ids,\n",
        "                      token_type_ids=None,\n",
        "                      attention_mask=b_input_mask,\n",
        "                      return_dict=True)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        predictions = torch.argmax(logits, dim=-1)\n",
        "\n",
        "        all_preds.extend(predictions.cpu().numpy())\n",
        "        all_labels.extend(b_labels.cpu().numpy())\n",
        "\n",
        "eval_time = format_time(time.time() - t0)\n",
        "print(f\"Evaluation complete. Total time: {eval_time}\")\n",
        "\n",
        "# --- 8. Display Results ---\n",
        "all_preds = np.array(all_preds)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "report = classification_report(all_labels, all_preds, target_names=[\"Negative (0)\", \"Positive (1)\"])\n",
        "\n",
        "print(\"\\n--- Phase 1: Binary Classification Report ---\")\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAFSGkysHk-8"
      },
      "source": [
        "## 5. Phase 2: 3-Class System Comparison (256-Token)\n",
        "\n",
        "This section loads the trained 256-token model and runs all three heuristic systems (Ratio, Logit, Weighting) on a 1,000-review sample to generate comparison data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Up2A0AgHk-8"
      },
      "outputs": [],
      "source": [
        "# --- 1. Setup: NLTK, Drive, Model, Tokenizer ---\n",
        "print(\"Downloading NLTK sentencizer (punkt)...\")\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "print(\"NLTK ready.\")\n",
        "\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "model_load_path = '/content/drive/My Drive/BERT_IMDB_Model_Trained_256_FP16_Optimized'\n",
        "print(f\"Loading trained model and tokenizer from: {model_load_path}\")\n",
        "model = BertForSequenceClassification.from_pretrained(model_load_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(model_load_path)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval() # Put model in evaluation mode\n",
        "\n",
        "\n",
        "print(\"Compiling model with torch.compile()...\")\n",
        "try:\n",
        "    model = torch.compile(model)\n",
        "    print(\"Model compiled successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"torch.compile() failed: {e}. Continuing without compilation.\")\n",
        "\n",
        "print(f\"Model loaded successfully on {device}\")\n",
        "\n",
        "\n",
        "# --- 2. Define Helper Functions for Model Prediction ---\n",
        "TOKENIZER_MAX_LENGTH = 256\n",
        "\n",
        "def predict_sentence_sentiment_binary(sentence_text):\n",
        "    \"\"\"Feeds a single sentence to the binary model and returns 0 or 1.\"\"\"\n",
        "    inputs = tokenizer(\n",
        "        sentence_text, return_tensors=\"pt\", truncation=True,\n",
        "        padding=\"max_length\", max_length=TOKENIZER_MAX_LENGTH\n",
        "    )\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
        "    prediction = torch.argmax(outputs.logits, dim=-1)\n",
        "    return prediction.cpu().item()\n",
        "\n",
        "def get_sentence_logits(sentence_text):\n",
        "    \"\"\"Feeds a single sentence to the binary model and returns its raw logits.\"\"\"\n",
        "    inputs = tokenizer(\n",
        "        sentence_text, return_tensors=\"pt\", truncation=True,\n",
        "        padding=\"max_length\", max_length=TOKENIZER_MAX_LENGTH\n",
        "    )\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask, return_dict=True)\n",
        "    return outputs.logits.squeeze().cpu().numpy()\n",
        "\n",
        "\n",
        "# --- 3. Define All Three Classification Systems ---\n",
        "\n",
        "# SYSTEM 1: Simple Ratio\n",
        "def classify_review_ratio(full_review_text, pos_threshold=0.7, neg_threshold=0.7):\n",
        "    \"\"\"Classifies based on the ratio of positive/negative sentences.\"\"\"\n",
        "    sentences = sent_tokenize(full_review_text)\n",
        "    if len(sentences) < 3:\n",
        "        pred = predict_sentence_sentiment_binary(full_review_text)\n",
        "        return \"POSITIVE\" if pred == 1 else \"NEGATIVE\"\n",
        "    sentence_predictions = [predict_sentence_sentiment_binary(s) for s in sentences]\n",
        "    if not sentence_predictions: return \"NEUTRAL\"\n",
        "    num_sentences = len(sentence_predictions)\n",
        "    num_positive = sum(sentence_predictions)\n",
        "    positive_ratio = num_positive / num_sentences\n",
        "    if positive_ratio >= pos_threshold: return \"POSITIVE\"\n",
        "    elif (1 - positive_ratio) >= neg_threshold: return \"NEGATIVE\"\n",
        "    else: return \"MIXED\"\n",
        "\n",
        "# SYSTEM 2: Logit-Based \"Neutral Zone\"\n",
        "def classify_review_logit(full_review_text, neutral_threshold=1.0, min_sentences=2):\n",
        "    \"\"\"Classifies based on confidence (logits) and co-occurrence.\"\"\"\n",
        "    sentences = sent_tokenize(full_review_text)\n",
        "    if not sentences: return \"NEUTRAL\"\n",
        "    confident_pos_count = 0\n",
        "    confident_neg_count = 0\n",
        "    for sentence in sentences:\n",
        "        logits = get_sentence_logits(sentence)\n",
        "        neg_score, pos_score = logits[0], logits[1]\n",
        "        score_difference = abs(pos_score - neg_score)\n",
        "        if score_difference >= neutral_threshold:\n",
        "            if pos_score > neg_score: confident_pos_count += 1\n",
        "            else: confident_neg_count += 1\n",
        "    if confident_pos_count >= min_sentences and confident_neg_count >= min_sentences: return \"MIXED\"\n",
        "    elif confident_pos_count > 0 and confident_neg_count == 0: return \"POSITIVE\"\n",
        "    elif confident_neg_count > 0 and confident_pos_count == 0: return \"NEGATIVE\"\n",
        "    else:\n",
        "        if confident_pos_count > confident_neg_count: return \"POSITIVE\"\n",
        "        elif confident_neg_count > confident_pos_count: return \"NEGATIVE\"\n",
        "        else: return \"NEUTRAL\"\n",
        "\n",
        "# SYSTEM 3: Positional Weighting + Co-occurrence\n",
        "def classify_review_weighting(full_review_text, positional_weight=2,\n",
        "                            mixed_pos_threshold=2, mixed_neg_threshold=2):\n",
        "    \"\"\"Classifies based on weighted co-occurrence, giving 2x weight to first/last sentences.\"\"\"\n",
        "    sentences = sent_tokenize(full_review_text)\n",
        "    if not sentences: return \"NEUTRAL\"\n",
        "    num_sentences = len(sentences)\n",
        "    weighted_pos_score = 0\n",
        "    weighted_neg_score = 0\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        current_weight = 1\n",
        "        if i == 0 or i == (num_sentences - 1):\n",
        "            current_weight = positional_weight\n",
        "        prediction = predict_sentence_sentiment_binary(sentence)\n",
        "        if prediction == 1: weighted_pos_score += current_weight\n",
        "        else: weighted_neg_score += current_weight\n",
        "    if (weighted_pos_score >= mixed_pos_threshold and\n",
        "        weighted_neg_score >= mixed_neg_threshold): return \"MIXED\"\n",
        "    elif weighted_pos_score > weighted_neg_score: return \"POSITIVE\"\n",
        "    elif weighted_neg_score > weighted_pos_score: return \"NEGATIVE\"\n",
        "    else: return \"NEUTRAL\"\n",
        "\n",
        "\n",
        "# --- 4. Load Raw Test Data and Run Comparison ---\n",
        "print(\"\\nLoading original (non-tokenized) IMDb test set...\")\n",
        "imdb_raw = load_dataset(\"imdb\")\n",
        "\n",
        "# Run on a 1,000-review sample for a quick comparison\n",
        "SAMPLE_SIZE = 1000\n",
        "test_reviews = imdb_raw['test'].shuffle(seed=42).select(range(SAMPLE_SIZE))\n",
        "\n",
        "results = []\n",
        "true_labels_map = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "\n",
        "print(f\"Running all 3 systems on {len(test_reviews)} test reviews...\")\n",
        "t0 = time.time() # Start timer\n",
        "\n",
        "for review in tqdm(test_reviews, desc=\"Analyzing Test Set\"):\n",
        "    text = review['text']\n",
        "    true_label = true_labels_map[review['label']]\n",
        "\n",
        "    pred_1 = classify_review_ratio(text)\n",
        "    pred_2 = classify_review_logit(text)\n",
        "    pred_3 = classify_review_weighting(text)\n",
        "\n",
        "    results.append({\n",
        "        \"true_label\": true_label,\n",
        "        \"system_1_ratio\": pred_1,\n",
        "        \"system_2_logit\": pred_2,\n",
        "        \"system_3_weighting\": pred_3,\n",
        "        \"text\": text\n",
        "    })\n",
        "\n",
        "total_time = format_time(time.time() - t0)\n",
        "print(f\"Analysis complete. Total time: {total_time}\")\n",
        "\n",
        "# --- 5. Generate and Print Comparison Report ---\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\" COMPARISON 1: OVERALL PREDICTION DISTRIBUTION (Sample size={SAMPLE_SIZE})\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nSystem 1 (Ratio) Distribution:\")\n",
        "print(df['system_1_ratio'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')\n",
        "print(\"\\nSystem 2 (Logit/Neutral) Distribution:\")\n",
        "print(df['system_2_logit'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')\n",
        "print(\"\\nSystem 3 (Weighting) Distribution:\")\n",
        "print(df['system_3_weighting'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\" COMPARISON 2: AGREEMENT WITH TRUE LABELS (Sample size={SAMPLE_SIZE})\")\n",
        "print(\"=\"*50)\n",
        "print(\"\\nSystem 1 (Ratio) vs. True Labels:\")\n",
        "print(pd.crosstab(df['true_label'], df['system_1_ratio']))\n",
        "print(\"\\nSystem 2 (Logit/Neutral) vs. True Labels:\")\n",
        "print(pd.crosstab(df['true_label'], df['system_2_logit']))\n",
        "print(\"\\nSystem 3 (Weighting) vs. True Labels:\")\n",
        "print(pd.crosstab(df['true_label'], df['system_3_weighting']))\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\" COMPARISON 3: HARD ERROR COUNT (Sample size={SAMPLE_SIZE})\")\n",
        "print(\"=\"*50)\n",
        "s1_errors = len(df[(df['true_label'] == \"POSITIVE\") & (df['system_1_ratio'] == \"NEGATIVE\")]) + \\\n",
        "            len(df[(df['true_label'] == \"NEGATIVE\") & (df['system_1_ratio'] == \"POSITIVE\")])\n",
        "print(f\"System 1 (Ratio) Hard Errors: {s1_errors}\")\n",
        "s2_errors = len(df[(df['true_label'] == \"POSITIVE\") & (df['system_2_logit'] == \"NEGATIVE\")]) + \\\n",
        "            len(df[(df['true_label'] == \"NEGATIVE\") & (df['system_2_logit'] == \"POSITIVE\")])\n",
        "print(f\"System 2 (Logit) Hard Errors: {s2_errors}\")\n",
        "s3_errors = len(df[(df['true_label'] == \"POSITIVE\") & (df['system_3_weighting'] == \"NEGATIVE\")]) + \\\n",
        "            len(df[(df['true_label'] == \"NEGATIVE\") & (df['system_3_weighting'] == \"POSITIVE\")])\n",
        "print(f\"System 3 (Weighting) Hard Errors: {s3_errors}\")\n",
        "\n",
        "# --- 6. Save Full Results to CSV for Qualitative Analysis ---\n",
        "results_save_path = f'/content/drive/My Drive/BERT_IMDB_Model_Trained_256_FP16_Optimized/sample_comparison_results_{SAMPLE_SIZE}.csv'\n",
        "print(f\"\\nSaving sample results to {results_save_path} for manual inspection...\")\n",
        "df.to_csv(results_save_path, index=False)\n",
        "print(\"Done.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4h10oUbHk-9"
      },
      "source": [
        "## 6. Phase 2: System 3 Validation (10,000-Sample)\n",
        "\n",
        "This final step validates the winning heuristic (System 3) on a larger 10,000-review sample to confirm the initial findings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nd8Mejq2Hk-9"
      },
      "outputs": [],
      "source": [
        "# --- 1. Setup: NLTK, Drive, Model, Tokenizer ---\n",
        "\n",
        "\n",
        "print(\"Downloading NLTK sentencizer (punkt)...\")\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "print(\"NLTK ready.\")\n",
        "\n",
        "# --- 2. Define Helper Function for Model Prediction ---\n",
        "TOKENIZER_MAX_LENGTH = 256\n",
        "\n",
        "def predict_sentence_sentiment_binary(sentence_text):\n",
        "    \"\"\"Feeds a single sentence to the binary model and returns 0 or 1.\"\"\"\n",
        "    inputs = tokenizer(\n",
        "        sentence_text, return_tensors=\"pt\", truncation=True,\n",
        "        padding=\"max_length\", max_length=TOKENIZER_MAX_LENGTH\n",
        "    )\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    attention_mask = inputs['attention_mask'].to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, token_type_ids=None, attention_mask=attention_mask)\n",
        "    prediction = torch.argmax(outputs.logits, dim=-1)\n",
        "    return prediction.cpu().item()\n",
        "\n",
        "# --- 3. Define ONLY System 3 (Weighting) ---\n",
        "def classify_review_weighting(full_review_text, positional_weight=2,\n",
        "                            mixed_pos_threshold=2, mixed_neg_threshold=2):\n",
        "    \"\"\"Classifies based on weighted co-occurrence, giving 2x weight to first/last sentences.\"\"\"\n",
        "    sentences = sent_tokenize(full_review_text)\n",
        "    if not sentences: return \"NEUTRAL\"\n",
        "    num_sentences = len(sentences)\n",
        "    weighted_pos_score = 0\n",
        "    weighted_neg_score = 0\n",
        "\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        current_weight = 1\n",
        "        if i == 0 or i == (num_sentences - 1):\n",
        "            current_weight = positional_weight\n",
        "        prediction = predict_sentence_sentiment_binary(sentence)\n",
        "        if prediction == 1: weighted_pos_score += current_weight\n",
        "        else: weighted_neg_score += current_weight\n",
        "\n",
        "    if (weighted_pos_score >= mixed_pos_threshold and\n",
        "        weighted_neg_score >= mixed_neg_threshold): return \"MIXED\"\n",
        "    elif weighted_pos_score > weighted_neg_score: return \"POSITIVE\"\n",
        "    elif weighted_neg_score > weighted_pos_score: return \"NEGATIVE\"\n",
        "    else: return \"NEUTRAL\"\n",
        "\n",
        "\n",
        "# --- 4. Load Raw Test Data and Run on 10,000 Samples ---\n",
        "print(\"\\nLoading original (non-tokenized) IMDb test set...\")\n",
        "imdb_raw = load_dataset(\"imdb\")\n",
        "\n",
        "\n",
        "SAMPLE_SIZE = 10000\n",
        "test_reviews = imdb_raw['test'].shuffle(seed=42).select(range(SAMPLE_SIZE))\n",
        "\n",
        "results = []\n",
        "true_labels_map = {0: \"NEGATIVE\", 1: \"POSITIVE\"}\n",
        "\n",
        "print(f\"Running System 3 on {len(test_reviews)} test reviews...\")\n",
        "t0 = time.time()\n",
        "\n",
        "for review in tqdm(test_reviews, desc=\"Analyzing 10k Test Set\"):\n",
        "    text = review['text']\n",
        "    true_label = true_labels_map[review['label']]\n",
        "\n",
        "\n",
        "    pred_3 = classify_review_weighting(text)\n",
        "\n",
        "    results.append({\n",
        "        \"true_label\": true_label,\n",
        "        \"system_3_weighting\": pred_3,\n",
        "        \"text\": text\n",
        "    })\n",
        "\n",
        "total_time = format_time(time.time() - t0)\n",
        "print(f\"Analysis complete. Total time: {total_time}\")\n",
        "\n",
        "# --- 5. Generate and Print Comparison Report ---\n",
        "df = pd.DataFrame(results)\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\" SYSTEM 3 RESULTS (Sample size={SAMPLE_SIZE})\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(\"\\nSystem 3 (Weighting) Distribution:\")\n",
        "print(df['system_3_weighting'].value_counts(normalize=True).mul(100).round(2).astype(str) + '%')\n",
        "\n",
        "print(\"\\nSystem 3 (Weighting) vs. True Labels:\")\n",
        "print(pd.crosstab(df['true_label'], df['system_3_weighting']))\n",
        "\n",
        "s3_errors = len(df[(df['true_label'] == \"POSITIVE\") & (df['system_3_weighting'] == \"NEGATIVE\")]) + \\\n",
        "            len(df[(df['true_label'] == \"NEGATIVE\") & (df['system_3_weighting'] == \"POSITIVE\")])\n",
        "print(f\"\\nSystem 3 (Weighting) Hard Errors: {s3_errors}\")\n",
        "\n",
        "# --- 6. Save Full Results to CSV for Qualitative Analysis ---\n",
        "results_save_path = f'/content/drive/My Drive/BERT_IMDB_Model_Trained_256_FP16_Optimized/final_system3_results_{SAMPLE_SIZE}.csv'\n",
        "print(f\"\\nSaving 10k results to {results_save_path} for manual inspection...\")\n",
        "df.to_csv(results_save_path, index=False)\n",
        "print(\"Done.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}